in this paper we address the issue of learning to rank for document
retrieval. in the task, a model is automatically created with some
training data and then is utilized for ranking of documents. the
goodness of a model is usually evaluated with performance 
measures such as map (mean average precision) and ndcg 
(normalized discounted cumulative gain). ideally a learning 
algorithm would train a ranking model that could directly optimize the
performance measures with respect to the training data. existing
methods, however, are only able to train ranking models by 
minimizing loss functions loosely related to the performance measures.
for example, ranking svm and rankboost train ranking 
models by minimizing classification errors on instance pairs. to deal
with the problem, we propose a novel learning algorithm within
the framework of boosting, which can minimize a loss function
directly defined on the performance measures. our algorithm, 
referred to as adarank, repeatedly constructs â€˜weak rankers" on the
basis of re-weighted training data and finally linearly combines the
weak rankers for making ranking predictions. we prove that the
training process of adarank is exactly that of enhancing the 
performance measure used. experimental results on four benchmark
datasets show that adarank significantly outperforms the baseline
methods of bm25, ranking svm, and rankboost.
