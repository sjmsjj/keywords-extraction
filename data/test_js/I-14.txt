the dominant existing routing strategies employed in 
peerto-peer(p2p) based information retrieval(ir) systems are
similarity-based approaches. in these approaches, agents
depend on the content similarity between incoming queries
and their direct neighboring agents to direct the distributed
search sessions. however, such a heuristic is myopic in that
the neighboring agents may not be connected to more 
relevant agents. in this paper, an online reinforcement-learning
based approach is developed to take advantage of the 
dynamic run-time characteristics of p2p ir systems as 
represented by information about past search sessions. 
specifically, agents maintain estimates on the downstream agents"
abilities to provide relevant documents for incoming queries.
these estimates are updated gradually by learning from the
feedback information returned from previous search sessions.
based on this information, the agents derive corresponding
routing policies. thereafter, these agents route the queries
based on the learned policies and update the estimates based
on the new routing policies. experimental results 
demonstrate that the learning algorithm improves considerably the
routing performance on two test collection sets that have
been used in a variety of distributed ir studies.
